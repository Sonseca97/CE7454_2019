{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05 : Advantageous Actor-Critic (A2C) - demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    file_name = 'A2C_actor_critic_demo.ipynb'\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    print(path_to_file)\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(torch.randint(10000,())) # random seed for pythorch random generator\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import gym\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from itertools import count\n",
    "\n",
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state: [ 0.03073904  0.00145001 -0.03088818 -0.03131252]\n",
      "t= 0 action= 0 state= [ 0.03077 -0.19322 -0.03151  0.25147] reward= 1.0 done= False\n",
      "t= 1 action= 1 state= [ 0.0269   0.00234 -0.02649 -0.05099] reward= 1.0 done= False\n",
      "t= 2 action= 0 state= [ 0.02695 -0.19239 -0.0275   0.23322] reward= 1.0 done= False\n",
      "t= 3 action= 0 state= [ 0.0231  -0.38711 -0.02284  0.5171 ] reward= 1.0 done= False\n",
      "t= 4 action= 1 state= [ 0.01536 -0.19167 -0.0125   0.21731] reward= 1.0 done= False\n",
      "t= 5 action= 0 state= [ 0.01153 -0.38661 -0.00815  0.50603] reward= 1.0 done= False\n",
      "t= 6 action= 1 state= [ 0.00379 -0.19138  0.00197  0.21079] reward= 1.0 done= False\n",
      "t= 7 action= 1 state= [-3.27300e-05  3.71557e-03  6.18426e-03 -8.12748e-02] reward= 1.0 done= False\n",
      "t= 8 action= 0 state= [ 4.15813e-05 -1.91494e-01  4.55876e-03  2.13353e-01] reward= 1.0 done= False\n",
      "t= 9 action= 0 state= [-0.00379 -0.38668  0.00883  0.50747] reward= 1.0 done= False\n",
      "t= 10 action= 1 state= [-0.01152 -0.19168  0.01898  0.21758] reward= 1.0 done= False\n",
      "t= 11 action= 1 state= [-0.01536  0.00316  0.02333 -0.06906] reward= 1.0 done= False\n",
      "t= 12 action= 1 state= [-0.01529  0.19794  0.02195 -0.35429] reward= 1.0 done= False\n",
      "t= 13 action= 0 state= [-0.01133  0.00251  0.01486 -0.05477] reward= 1.0 done= False\n",
      "t= 14 action= 1 state= [-0.01128  0.19742  0.01376 -0.34272] reward= 1.0 done= False\n",
      "t= 15 action= 1 state= [-0.00733  0.39234  0.00691 -0.63104] reward= 1.0 done= False\n",
      "t= 16 action= 1 state= [ 5.11918e-04  5.87368e-01 -5.71058e-03 -9.21534e-01] reward= 1.0 done= False\n",
      "t= 17 action= 1 state= [ 0.01226  0.78257 -0.02414 -1.21601] reward= 1.0 done= False\n",
      "t= 18 action= 0 state= [ 0.02791  0.58776 -0.04846 -0.93098] reward= 1.0 done= False\n",
      "t= 19 action= 0 state= [ 0.03967  0.39333 -0.06708 -0.65392] reward= 1.0 done= False\n",
      "t= 20 action= 1 state= [ 0.04753  0.58932 -0.08016 -0.96694] reward= 1.0 done= False\n",
      "t= 21 action= 0 state= [ 0.05932  0.39536 -0.0995  -0.70048] reward= 1.0 done= False\n",
      "t= 22 action= 0 state= [ 0.06723  0.20175 -0.11351 -0.4407 ] reward= 1.0 done= False\n",
      "t= 23 action= 1 state= [ 0.07126  0.39828 -0.12232 -0.7669 ] reward= 1.0 done= False\n",
      "t= 24 action= 0 state= [ 0.07923  0.20503 -0.13766 -0.51507] reward= 1.0 done= False\n",
      "t= 25 action= 0 state= [ 0.08333  0.01209 -0.14796 -0.26874] reward= 1.0 done= False\n",
      "t= 26 action= 1 state= [ 0.08357  0.20898 -0.15334 -0.60419] reward= 1.0 done= False\n",
      "t= 27 action= 1 state= [ 0.08775  0.40587 -0.16542 -0.94098] reward= 1.0 done= False\n",
      "t= 28 action= 1 state= [ 0.09587  0.60279 -0.18424 -1.28073] reward= 1.0 done= False\n",
      "t= 29 action= 1 state= [ 0.10792  0.79972 -0.20985 -1.62499] reward= 1.0 done= True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Env parameters\n",
    "env_seed = 1\n",
    "render = True # display on\n",
    "render = False # display off\n",
    "\n",
    "#Initialize the environment with the same seed/initialization value\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(env_seed)\n",
    "\n",
    "#Reset the environment\n",
    "state = env.reset() \n",
    "print('init state:',state)\n",
    "\n",
    "#Rollout one episode until it finishes \n",
    "for t in count():  \n",
    "    action = torch.LongTensor(1).random_(0,2).item() # randomly generated action=a in {0,1}\n",
    "    state, reward, done, _ = env.step(action) # receive next state=s' and reward=r\n",
    "    print('t=',t, 'action=',action, 'state=',np.array_str(state, precision=5), 'reward=',reward, 'done=',done )\n",
    "    if render:\n",
    "        env.render() # see the state\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the policy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActorCritic_NN(\n",
      "  (fc1_p): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (fc2_p): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (fc1_q_sv): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (fc2_q_sv): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (fc1_q_s): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (fc2_q_s): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "batch_episode_lengths: [39, 26, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# class of policy network\n",
    "class ActorCritic_NN(nn.Module): \n",
    "    \n",
    "    def __init__(self, net_parameters):\n",
    "        super(ActorCritic_NN, self).__init__()\n",
    "        input_dim = net_parameters['input_dim']\n",
    "        hidden_dim = net_parameters['hidden_dim']\n",
    "        output_dim = net_parameters['output_dim']\n",
    "        # policy network\n",
    "        self.fc1_p = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_p = nn.Linear(hidden_dim, output_dim)\n",
    "        # state-value function network\n",
    "        self.fc1_q_sv = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_q_sv = nn.Linear(hidden_dim, output_dim)\n",
    "        # state function network\n",
    "        self.fc1_q_s = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_q_s = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward_policy(self, x):\n",
    "        x = torch.relu(self.fc1_p(x))\n",
    "        actions_score = self.fc2_p(x)\n",
    "        actions_prob = torch.softmax(actions_score, dim=1)\n",
    "        return actions_prob\n",
    "    \n",
    "    def forward_Q_sv(self, x):\n",
    "        x = torch.relu(self.fc1_q_sv(x))\n",
    "        Q_scores = self.fc2_q_sv(x) # scores over actions \n",
    "        return Q_scores\n",
    "    \n",
    "    def forward_Q_s(self, x):\n",
    "        x = torch.relu(self.fc1_q_s(x))\n",
    "        Q_scores = self.fc2_q_s(x) # scores over actions \n",
    "        return Q_scores\n",
    "    \n",
    "    def select_action(self, state): # select action w/ policy network\n",
    "        probs = self.forward_policy(state) # probability of action a in state s\n",
    "        bernoulli_sampling = torch.distributions.Categorical(probs) \n",
    "        action = bernoulli_sampling.sample() # sample action a with Bernoulli sampling\n",
    "        return action\n",
    "\n",
    "    def loss(self, batch):\n",
    "        gamma = opt_parameters['gamma']\n",
    "        nb_episodes_per_batch = len(batch.states)\n",
    "        batch_losses = []\n",
    "        for episode in range(nb_episodes_per_batch):\n",
    "            episode_states = torch.stack( batch.states[episode] ).float() #size=B x 4     \n",
    "            episode_next_states = torch.stack( batch.next_states[episode] ).float() #size=B x 4  \n",
    "            episode_actions = torch.stack( batch.actions[episode] ).long() #size=B\n",
    "            episode_rewards = - torch.stack( batch.rewards[episode] ).float() #size=B\n",
    "            episode_dones = torch.stack( batch.dones[episode] ).float() #size=B\n",
    "            R = 0; policy_loss = []; rewards = []\n",
    "            for r in batch.rewards[episode][::-1]: # compute the discarded award at each time step\n",
    "                R = r + gamma * R\n",
    "                rewards.insert(0, R)\n",
    "            episode_discounted_rewards = torch.tensor(rewards).float() #size=B\n",
    "            episode_next_actions = self.select_action(episode_next_states) #size=B\n",
    "            Q = self.forward_Q_sv(episode_states).gather(dim=1,index=episode_actions.unsqueeze(1)) # Qv(a|s), size=B x 1\n",
    "            Q_target = episode_rewards.unsqueeze(1) + gamma *  \\\n",
    "                self.forward_Q_sv(episode_next_states).gather(dim=1,index=episode_next_actions.unsqueeze(1)) * episode_dones.unsqueeze(1)\n",
    "            Q_state = self.forward_Q_s(episode_states)\n",
    "            logP = torch.log( actorcritic_net.forward_policy(episode_states).gather(dim=1,index=episode_actions.unsqueeze(1)) )\n",
    "            loss1 = ( -logP * (Q-Q_state).detach() ).mean()\n",
    "            loss2 = nn.MSELoss()(Q,Q_target.detach())\n",
    "            loss3 = nn.MSELoss()(Q_state,episode_discounted_rewards.unsqueeze(1).detach())\n",
    "            loss = loss1 + loss2 + loss3\n",
    "            batch_losses.append(loss)\n",
    "        loss = torch.stack(batch_losses).mean()\n",
    "        return loss\n",
    "\n",
    "        \n",
    "# class of rollout episodes\n",
    "class Rollout_Episodes():\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super(Rollout_Episodes, self).__init__()\n",
    "    \n",
    "    def rollout_batch_episodes(self, env, opt_parameters, actorcritic_net, write_memory=True):\n",
    "        # storage structure of all episodes (w/ different lengths)\n",
    "        nb_episodes_per_batch = opt_parameters['nb_episodes_per_batch']\n",
    "        env_seeds = opt_parameters['env_seed']\n",
    "        batch = DotDict()\n",
    "        batch.states=[];  batch.actions=[]; batch.next_states=[]; batch.rewards=[]; batch.dones=[]\n",
    "        batch_episode_lengths = []\n",
    "        for episode in range(nb_episodes_per_batch):\n",
    "            states=[]; actions=[]; next_states=[]; rewards=[]; dones = []\n",
    "            env.seed(env_seeds[episode].item()) # start with random seed\n",
    "            state = env.reset() # reset environment\n",
    "            for t in range(1000): # rollout one episode \n",
    "                state_pytorch = torch.from_numpy(state).float().unsqueeze(0) # state=s\n",
    "                action = actorcritic_net.select_action(state_pytorch).item() # select action=a from state=s\n",
    "                next_state, reward, done, _ = env.step(action) # receive next state=s' and reward=r\n",
    "                done_mask = 0.0 if done else 1.0\n",
    "                states.append(torch.tensor(state))\n",
    "                actions.append(torch.tensor(action))\n",
    "                next_states.append(torch.tensor(next_state))\n",
    "                rewards.append(torch.tensor(reward))\n",
    "                dones.append(torch.tensor(done_mask))\n",
    "                state = next_state\n",
    "                if done:\n",
    "                    batch_episode_lengths.append(t)\n",
    "                    break\n",
    "            batch.states.append(states)\n",
    "            batch.actions.append(actions)\n",
    "            batch.next_states.append(next_states)\n",
    "            batch.rewards.append(rewards)\n",
    "            batch.dones.append(dones)\n",
    "        return batch_episode_lengths, batch\n",
    "\n",
    "        \n",
    "    \n",
    "# network parameters\n",
    "net_parameters = {}\n",
    "net_parameters['input_dim'] = 4\n",
    "net_parameters['hidden_dim'] = 128\n",
    "net_parameters['output_dim'] = 2\n",
    "\n",
    "# instantiate network\n",
    "actorcritic_net = ActorCritic_NN(net_parameters)\n",
    "print(actorcritic_net)\n",
    "\n",
    "# instantiate rollout\n",
    "rollout_policy_net = Rollout_Episodes()\n",
    "\n",
    "# optimization parameters\n",
    "opt_parameters = {}\n",
    "opt_parameters['nb_episodes_per_batch'] = 3\n",
    "opt_parameters['env_seed'] = torch.LongTensor(opt_parameters['nb_episodes_per_batch']).random_(1,10000)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "batch_episode_lengths, batch = rollout_policy_net.rollout_batch_episodes(env, opt_parameters, actorcritic_net)\n",
    "#print('batch:',batch)\n",
    "print('batch_episode_lengths:',batch_episode_lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_episode_lengths: [14, 29, 16]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# optimization parameters\n",
    "opt_parameters = {}\n",
    "opt_parameters['lr'] = 0.001\n",
    "opt_parameters['nb_episodes_per_batch'] = 3\n",
    "opt_parameters['env_seed'] = torch.LongTensor(opt_parameters['nb_episodes_per_batch']).random_(1,10000)\n",
    "opt_parameters['gamma'] = 0.99\n",
    "\n",
    "batch_episode_lengths, batch = rollout_policy_net.rollout_batch_episodes(env, opt_parameters, actorcritic_net)\n",
    "#print('batch:',batch)\n",
    "print('batch_episode_lengths:',batch_episode_lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(141.9592, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loss\n",
    "loss = actorcritic_net.loss(batch)\n",
    "print('loss:',loss)\n",
    "\n",
    "# Backward pass\n",
    "lr = opt_parameters['lr']\n",
    "optimizer = torch.optim.Adam(actorcritic_net.parameters(), lr=lr)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(env, actorcritic_net, opt_parameters):\n",
    "    \"\"\"\n",
    "    train one epoch\n",
    "    \"\"\"\n",
    "    actorcritic_net.train()\n",
    "    epoch_loss = 0\n",
    "    nb_data = 0\n",
    "    epoch_episode_length = 0\n",
    "    epoch_episode_lengths = []\n",
    "    nb_batches_per_epoch = opt_parameters['nb_batches_per_epoch']\n",
    "    for iter in range(nb_batches_per_epoch):\n",
    "        batch_episode_lengths, batch = \\\n",
    "            rollout_policy_net.rollout_batch_episodes(env, opt_parameters, actorcritic_net)\n",
    "        loss = actorcritic_net.loss(batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "        nb_data += len(batch_episode_lengths)\n",
    "        epoch_episode_length += torch.tensor(batch_episode_lengths).float().sum()\n",
    "        epoch_episode_lengths.append(epoch_episode_length)\n",
    "    epoch_loss /= nb_data\n",
    "    epoch_episode_length /= nb_data\n",
    "    return epoch_loss, epoch_episode_length, epoch_episode_lengths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done.\n",
      "Last episode length is 395.20001220703125, epoch is 45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# network parameters\n",
    "net_parameters = {}\n",
    "net_parameters['input_dim'] = 4\n",
    "net_parameters['hidden_dim'] = 256\n",
    "net_parameters['output_dim'] = 2\n",
    "\n",
    "# instantiate network\n",
    "actorcritic_net = ActorCritic_NN(net_parameters)\n",
    "print(actorcritic_net)\n",
    "\n",
    "# optimization parameters\n",
    "opt_parameters = {}\n",
    "opt_parameters['lr'] = 0.0005\n",
    "opt_parameters['nb_episodes_per_batch'] = 1\n",
    "opt_parameters['nb_batches_per_epoch'] = 50\n",
    "opt_parameters['env_seed'] = torch.LongTensor(opt_parameters['nb_episodes_per_batch']).random_(1,10000)\n",
    "opt_parameters['gamma'] = 0.99\n",
    "\n",
    "optimizer = torch.optim.Adam(actorcritic_net.parameters(), lr=opt_parameters['lr'] )\n",
    "\n",
    "# select maximum episode length to learn\n",
    "env = gym.make('CartPole-v0')\n",
    "env._max_episode_steps = 400 # 200 400\n",
    "env.spec.reward_threshold = 0.975* env._max_episode_steps\n",
    "print('env._max_episode_steps',env._max_episode_steps)\n",
    "\n",
    "# train loop\n",
    "all_epoch_lengths = []\n",
    "start = time.time()\n",
    "for epoch in range(500): \n",
    "    \n",
    "    # train one epoch\n",
    "    epoch_train_loss, epoch_episode_length, epoch_episode_lengths = train_one_epoch(env, actorcritic_net, opt_parameters)\n",
    " \n",
    "    # stop training when reward is high\n",
    "    if epoch_episode_length > env.spec.reward_threshold:\n",
    "        print('Training done.')\n",
    "        print(\"Last episode length is {}, epoch is {}\".\n",
    "              format(epoch_episode_length, epoch))\n",
    "        break\n",
    "\n",
    "    # print intermediate info\n",
    "    if not epoch%1:\n",
    "        print('Epoch: {}, time: {:.4f}, train_loss: {:.4f}, episode_length: {:.4f}'.format(epoch, time.time()-start, epoch_train_loss, epoch_episode_length))\n",
    "        \n",
    "    # plot all epochs\n",
    "    all_epoch_lengths.append(epoch_episode_length)\n",
    "    if not epoch%1:\n",
    "        plt.figure(2)\n",
    "        plt.title('Training...')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Length of episodes batch')\n",
    "        plt.plot(torch.Tensor(all_epoch_lengths).numpy())\n",
    "        plt.pause(0.001)\n",
    "        display.clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last episode length is 395.20001220703125, epoch is 45\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final plot\n",
    "plt.figure(2)\n",
    "plt.title('Training...')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Length of episodes batch')\n",
    "plt.plot(torch.Tensor(all_epoch_lengths).numpy())\n",
    "print(\"Last episode length is {}, epoch is {}\".format(epoch_episode_length, epoch))\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env._max_episode_steps = 5000\n",
    "\n",
    "state = env.reset() # reset environment\n",
    "for t in range(env._max_episode_steps): # rollout one episode until it finishes or stop after 200 steps\n",
    "    state_pytorch = torch.from_numpy(state).float().unsqueeze(0) # state=s\n",
    "    action = actorcritic_net.eval().select_action(state_pytorch).item()\n",
    "    state, reward, done, _ = env.step(action) # receive next state=s' and reward=r\n",
    "    env.render() # visualize state\n",
    "    if done:\n",
    "        print(t)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
